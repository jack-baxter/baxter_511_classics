{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNf3TYLEflPb"
      },
      "outputs": [],
      "source": [
        "#Jack Baxter\n",
        "#Final Project: AAI 511\n",
        "#11 August 2025"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import necessary packages\n",
        "import pretty_midi\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.layers import LSTM, TimeDistributed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score"
      ],
      "metadata": {
        "id": "XOtWo_13fufU"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize connection to google drive data\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMEnokTmneil",
        "outputId": "1b14af65-7ccc-4b71-88e3-c0bccc6a135e"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create main dataframe for piano rolls and composer id\n",
        "main_music = pd.DataFrame(columns = ['song', 'composer_id'])"
      ],
      "metadata": {
        "id": "q6DFJSw-gYzH"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize standard midi & piano roll parameters\n",
        "hz = 100\n",
        "timesteps = 4000\n",
        "pitchrange = 128"
      ],
      "metadata": {
        "id": "08_PCwzehHzZ"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define function to get piano roll from midi file\n",
        "#function created by LLM (xAI, 2025)\n",
        "def get_piano_roll(midi_path, fs=100, fixed_length=4000):\n",
        "    try:\n",
        "        midi_data = pretty_midi.PrettyMIDI(midi_path)\n",
        "        piano_roll = midi_data.get_piano_roll(fs=fs)\n",
        "        piano_roll = piano_roll / 127.0\n",
        "        current_length = piano_roll.shape[1]\n",
        "        if current_length < fixed_length:\n",
        "            padded = np.zeros((pitchrange, fixed_length))\n",
        "            padded[:, :current_length] = piano_roll\n",
        "            return padded\n",
        "        else:\n",
        "            return piano_roll[:, :fixed_length]\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {midi_path}: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "PS4q7PL5hhKC"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#previous dataset append function - not used in final\n",
        "piano_roll = get_piano_roll(midi_path, hz, pitchrange)\n",
        "if piano_roll is not None:\n",
        "    new_row = pd.DataFrame({\n",
        "        'song': [piano_roll],\n",
        "        'composer_id': [composer_id]\n",
        "    })\n",
        "    main_music = pd.concat([main_music, new_row], ignore_index=True)\n",
        "print(main_music)\n",
        "print(\"\\nDataFrame Info:\")\n",
        "print(main_music.dtypes)\n",
        "print(\"\\nShape of first piano roll:\", main_music['song'][0].shape if not main_music.empty else \"No data\")\n",
        "print(main_music.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EYXX241Fhuxt",
        "outputId": "690d5b6e-da4b-40b8-ca35-8cad02fa30fb"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                song composer_id\n",
            "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...           1\n",
            "\n",
            "DataFrame Info:\n",
            "song           object\n",
            "composer_id    object\n",
            "dtype: object\n",
            "\n",
            "Shape of first piano roll: (128, 128)\n",
            "                                                song composer_id\n",
            "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...           1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define function to evaluate final model\n",
        "#function created by LLM (xAI, 2025)\n",
        "def evaluate_model(model, X_test, y_test, model_name):\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_test_classes = np.argmax(y_test, axis=1)\n",
        "    accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
        "    precision = precision_score(y_test_classes, y_pred_classes, average='weighted')\n",
        "    recall = recall_score(y_test_classes, y_pred_classes, average='weighted')\n",
        "    print(f\"{model_name} Performance:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print()\n",
        "    return accuracy, precision, recall"
      ],
      "metadata": {
        "id": "q5HVgNTnouec"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#establish data file path, specifiy piano roll hyper param, initialize list for\n",
        "#data, iterate through directory and convert midi files to piano rolls\n",
        "#bach data\n",
        "data_dir = '/content/drive/My Drive/Bach'\n",
        "data = []\n",
        "fs = 100\n",
        "fixed_length = 4000\n",
        "compid = 1\n",
        "for file_name in os.listdir(data_dir):\n",
        "    midi_path = os.path.join(data_dir, file_name)\n",
        "    piano_roll = get_piano_roll(midi_path, fs, fixed_length)\n",
        "    if piano_roll is not None:\n",
        "        composer_id = compid\n",
        "        data.append({'song': piano_roll, 'composer_id': composer_id})"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2kQJ1NbcmBt2"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#establish data file path, specifiy piano roll hyper param, initialize list for\n",
        "#data, iterate through directory and convert midi files to piano rolls\n",
        "#beethoven data\n",
        "data_dir = '/content/drive/My Drive/Beethoven'\n",
        "fs = 100\n",
        "fixed_length = 4000\n",
        "compid = 2\n",
        "max_entries = 20\n",
        "for file_name in os.listdir(data_dir):\n",
        "    midi_path = os.path.join(data_dir, file_name)\n",
        "    piano_roll = get_piano_roll(midi_path, fs, fixed_length)\n",
        "    if piano_roll is not None:\n",
        "        composer_id = compid\n",
        "        data.append({'song': piano_roll, 'composer_id': composer_id})\n",
        "    if len(data) >= max_entries:  # Stop after collecting 10 valid entries\n",
        "        break"
      ],
      "metadata": {
        "id": "BK1MxMeBpfIg"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#establish data file path, specifiy piano roll hyper param, initialize list for\n",
        "#data, iterate through directory and convert midi files to piano rolls\n",
        "#chopin data\n",
        "data_dir = '/content/drive/My Drive/Chopin'\n",
        "fs = 100\n",
        "fixed_length = 4000\n",
        "compid = 3\n",
        "max_entries = 30\n",
        "for file_name in os.listdir(data_dir):\n",
        "    midi_path = os.path.join(data_dir, file_name)\n",
        "    piano_roll = get_piano_roll(midi_path, fs, fixed_length)\n",
        "    if piano_roll is not None:\n",
        "        composer_id = compid\n",
        "        data.append({'song': piano_roll, 'composer_id': composer_id})\n",
        "    if len(data) >= max_entries:  # Stop after collecting 10 valid entries\n",
        "        break"
      ],
      "metadata": {
        "id": "Cq53-mMcprap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9a8eff2-d740-4ac1-86a6-75ed9c2d613a"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#establish data file path, specifiy piano roll hyper param, initialize list for\n",
        "#data, iterate through directory and convert midi files to piano rolls\n",
        "#mozart data\n",
        "data_dir = '/content/drive/My Drive/Mozart'\n",
        "fs = 100\n",
        "fixed_length = 4000\n",
        "compid = 4\n",
        "max_entries = 40\n",
        "for file_name in os.listdir(data_dir):\n",
        "    midi_path = os.path.join(data_dir, file_name)\n",
        "    piano_roll = get_piano_roll(midi_path, fs, fixed_length)\n",
        "    if piano_roll is not None:\n",
        "        composer_id = compid\n",
        "        data.append({'song': piano_roll, 'composer_id': composer_id})\n",
        "    if len(data) >= max_entries:  # Stop after collecting 10 valid entries\n",
        "        break"
      ],
      "metadata": {
        "id": "fQY1jZjFpt6I"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#inspect dataframe\n",
        "main_music = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "clGgoGh0p2tN"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#inspect/evaluate dataframe\n",
        "print(main_music)\n",
        "print(main_music.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGdmlXYLqBTT",
        "outputId": "ae2dbb71-5d53-450c-9b92-77594007a70b"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 song  composer_id\n",
            "0   [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            1\n",
            "1   [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            1\n",
            "2   [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            1\n",
            "3   [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            1\n",
            "4   [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            1\n",
            "5   [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            1\n",
            "6   [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            1\n",
            "7   [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            1\n",
            "8   [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            1\n",
            "9   [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            1\n",
            "10  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            2\n",
            "11  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            2\n",
            "12  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            2\n",
            "13  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            2\n",
            "14  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            2\n",
            "15  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            2\n",
            "16  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            2\n",
            "17  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            2\n",
            "18  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            2\n",
            "19  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            2\n",
            "20  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            3\n",
            "21  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            3\n",
            "22  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            3\n",
            "23  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            3\n",
            "24  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            3\n",
            "25  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            3\n",
            "26  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            3\n",
            "27  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            3\n",
            "28  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            3\n",
            "29  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            3\n",
            "30  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            4\n",
            "31  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            4\n",
            "32  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            4\n",
            "33  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            4\n",
            "34  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            4\n",
            "35  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            4\n",
            "36  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            4\n",
            "37  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            4\n",
            "38  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            4\n",
            "39  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            4\n",
            "song           object\n",
            "composer_id     int64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define X and Y vars for training\n",
        "#one-hot encode y vars for training clarity\n",
        "x = np.array(main_music['song'].tolist())\n",
        "y = main_music['composer_id'].values - 1\n",
        "y = to_categorical(y, num_classes=4)\n",
        "#investigate format\n",
        "print(y)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNJfRNHcl8Zs",
        "outputId": "0d6be06a-f711-4129-a80a-d5189389d4bd"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]]\n",
            "(40, 128, 4000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#split train/test data\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "zi3ZhPF8mrau"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#format data for CNN expansion (additional channel for CNN format)\n",
        "#both training and test data\n",
        "xtraincnn = np.expand_dims(xtrain, axis=-1)\n",
        "xtestcnn = np.expand_dims(xtest, axis=-1)"
      ],
      "metadata": {
        "id": "R_kWbStAnBw_"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize CNN model, sequential with multiple layers and activation functions\n",
        "cnn_model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(xtrain.shape[1], xtrain.shape[2], 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(4, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gb6-kehKnL_Z",
        "outputId": "2d56ec76-d78d-44a6-eadc-675354ce5c12"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize LSTM model, sequential with multiple layers and activation functions\n",
        "lstm_model = Sequential([\n",
        "    LSTM(128, input_shape=(xtrain.shape[1], xtrain.shape[2]), return_sequences=True),\n",
        "    LSTM(64),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(4, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYki_PKGnS9s",
        "outputId": "45a2557a-676c-4663-aaba-e07d2b1e6f5a"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compile models with adam optimizer and CCentropy\n",
        "#include epoch accuracy metric for real time data monitoring\n",
        "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "cnn_model.fit(xtraincnn, ytrain, epochs=10, batch_size=32, validation_split=0.2)\n",
        "lstm_model.fit(xtrain, ytrain, epochs=10, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIpnnnAxneZ9",
        "outputId": "b7063501-66d8-4ded-8bb3-872903a95cd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation metrics CNN\n",
        "cnn_accuracy, cnn_precision, cnn_recall = evaluate_model(cnn_model, xtestcnn, ytest, \"CNN Model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0HlbCtTo5oP",
        "outputId": "fe556417-6d51-45fc-b93b-5683566634dd"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529ms/step\n",
            "CNN Model Performance:\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation metrics LSTM\n",
        "lstm_accuracy, lstm_precision, lstm_recall = evaluate_model(lstm_model, xtest, ytest, \"LSTM Model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZmijXc3o75h",
        "outputId": "e16c55b8-b0ed-4048-cfac-3b1d29c86422"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 800ms/step\n",
            "LSTM Model Performance:\n",
            "Accuracy: 0.0000\n",
            "Precision: 0.0000\n",
            "Recall: 0.0000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparam adjustments and retraining for CNN:\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, AveragePooling2D\n",
        "cnn_model2 = Sequential([\n",
        "    Conv2D(32, (3, 3), input_shape=(xtrain.shape[1], xtrain.shape[2], 1)),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    AveragePooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3)),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    AveragePooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3)),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    AveragePooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(4, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "zHSa3UoSrD-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adjusted epochs 10->20\n",
        "cnn_model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "cnn_model2.fit(xtraincnn, ytrain, epochs=20, batch_size=32, validation_split=0.2)\n",
        "cnn_accuracy, cnn_precision, cnn_recall = evaluate_model(cnn_model2, xtestcnn, ytest, \"CNN Model 2\")"
      ],
      "metadata": {
        "id": "6Gq0jUT31FFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparam adjustments and retraining for LSTM:\n",
        "lstm_model2 = Sequential([\n",
        "    LSTM(128, input_shape=(xtrain.shape[1], xtrain.shape[2]),\n",
        "         return_sequences=True, dropout=0.3),\n",
        "    LSTM(128, dropout=0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(4, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "3A7o-ISD00Kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adjusted epochs 10->20\n",
        "lstm_model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "lstm_model2.fit(xtrain, ytrain, epochs=20, batch_size=32, validation_split=0.2)\n",
        "lstm_accuracy, lstm_precision, lstm_recall = evaluate_model(lstm_model2, xtest, ytest, \"LSTM Model 2\")"
      ],
      "metadata": {
        "id": "pFamAbBj7cZi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}